# General Assembly Data Science Class 
6/14/2016 to 8/18/2016

**Instructor: Hamed Hasheminia**


Tuesdays | Thursdays
--- | ---
6/14: Data Science - Introduction Part I | 6/16 Data Science - Introduction Part II
6/21: Linear Regression Lines Part I | 6/23: Linear Regression Lines Part II 
6/28: Model Selection | 6/30: Missing Data and Imputation
7/5: K-Nearest Neighbors | 7/7: Logistic Regression Part I
7/12: Logistic Regression Part II | 7/14: In Class Project 
7/19: Decision Trees Part I | 7/21: Decision Trees Part II
7/26: Natural Language Processing | 7/28: Time Series Models
8/2: Principal Component Analysis | 8/4: Data Visualization
8/9: Naive Bayes | 8/11: Course Review
8/16: Final Project Presentations I | 8/18: Final Project Presentations II




##Lecture 1 Summary (Data Science - Introduction Part I)


 - Data Science - meaning
 - Continuous, Discrete and Qualitative Data
 - Supervised vs Unsupervised Learning
 - Classification vs Regression
 - Time series vs cross-sectional data
 - Numpy
 - Pandas
 
**Resources**
 
 - [Lecture 1 - Introduction - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%201%20-%20Introduction.pptx)
 - [Intro Numpy - Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%201_Intro_Numpy.ipynb)
 - [Intro Numpy - Code - Solutions](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%201_Intro_Numpy_Solutions.ipynb)
 - [Intro Pandas - Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%201_Intro_Pandas.ipynb)
 - [InClass Practice Code - Pandas](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%201-Practice-Code.ipynb)
 - [InClass Practice Code - Solutions](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%201-Practice-Code-Solutions.ipynb)
 
**Set up GitHub - Self-study guide**

 - [Lecture 0 - GitHub - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%200%20-%20GitHub%20-%20Self-study.pptx) 
 - [excellent videos to set-up github](https://www.youtube.com/playlist?list=PL5-da3qGB5IBLMp7LtN8Nc3Efd4hJq0kD). Students who have not used GitHub before must watch these videos.
 - A hands-on introduction to Git and GitHub, and how to make them work together! More Git resources for beginners [here](http://www.dataschool.io/tag/git/)
 
**Pre-work for second lecture**
 
 - Review all lecture notes including [Lecture Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%201%20-%20Introduction.pptx), [Numpy notebook](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture1_Intro_Numpy.ipynb), and [Pandas notebook](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%201-Practice-Code.ipynb)
 - Finish self-study Github guidlines listed above
 - **Finish** [Inclass Practice Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%201-Practice-Code.ipynb)
 - Review [final project requirements](https://github.com/ga-students/DS-SF-24/blob/master/final-projects/readme.md). You can find timelines for final project at slide 11 of [Lecture 1](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%201%20-%20Introduction.pptx) PowerPoint Slides
  
**Additional Resources**

 - [Official Pandas Tutorials](http://pandas.pydata.org/pandas-docs/stable/tutorials.html). Wes & Company's selection of tutorials and lectures
 - [Julia Evans Pandas Cookbook](https://github.com/jvns/pandas-cookbook). Great resource with examples from weather, bikes and 311 calls
 - [Learn Pandas Tutorials](https://bitbucket.org/hrojas/learn-pandas). A great series of Pandas tutorials from Dave Rojas
 - [Research Computing Python Data PYNBs](https://github.com/ResearchComputing/Meetup-Fall-2013/tree/master/python). A super awesome set of python notebooks from a meetup-based course exclusively devoted to pandas
 
 
## Lecture 2 Summary (Data Science Intorduction - Part II)
- Measures of central tendency (Mean, Median, Mode, Quartiles, Percentiles)- Measures of Variability (IQR, Standard Deviation, Variance)- Skewness Coefficient - Boxplots, Histograms, Scatterplots- Central Limit Theorem- Class/Dummy Variables
- Walkthrough describing and visualizing data in Pandas

**Resources**
 
 - [Lecture 2 - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%202%20-%20Introduction%20-%20Part%202.pptx) 
 - [Basic Statistics - Part 2 - Lab Codes](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%202%20-%20Intro.ipynb) 
 - [Basic Statistics - Part 2 - Practice Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%202-%20Intro%20-Practice-Code.ipynb)
 - [Basic Statistics - Part 2 - Practice Code - Solutions](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%202-%20Intro%20-Practice-Code-Solutions.ipynb)


**HW 1 is Assigned**

 - Please read and follow instructions from [readme](https://github.com/ga-students/DS-SF-24/blob/master/HW%20Assignments/HW1/readme.md)
 - This homework is due on June 23rd, 2016 at 6:30PM

**Additional Resources**

 - [Here](http://matplotlib.org/resources/index.html) you can find valuable resources for matplotlib
 - [A good Video](https://www.youtube.com/watch?v=Pujol1yC1_A) on Centeral Limit Theorem
 

## Lecture 3 Summary (Linear Regression Lines - Part I)
- Linear Regression lines
- Single Variable and Multi-Variable Regression Lines
- Capture non-linearity using Linear Regression lines.
- Interpretting regression coefficients
- Dealing with dummy variables in regression lines
- intro on sklearn and searborn library

**Resources**
 
- [Lecture 3 - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%203%20-%20Linear%20Regression%20-%20Part%201.pptx) 
- [Linear Regression - Part I - Lab Codes](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%203%20-%20Linear%20Regression%20-%20Part%201.ipynb) 
- [Linear Regression - Part I - Practice Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%203-Practice-Code.ipynb)
- [Linear Regression - Part I - Practice Solutions](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%203-Practice-Solution.ipynb)

**Additional Resources**

- My videos on regression lines. [Video 1](https://www.youtube.com/watch?v=QRzaKZRqens), [Video 2](https://www.youtube.com/watch?v=F6ceTd56vc0)
- This is an [excellent book](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf). In Lecture 3 and Lecture 4, we are going to cover Chapter 3 of this textbook.
- [Seaborn](https://web.stanford.edu/~mwaskom/software/seaborn/api.html) 
- [Weighted Least Square Method (WLS)](http://www.econ.uiuc.edu/~wsosa/econ471/GLSHeteroskedasticity.pdf) 
- Good resource for [heteroskedasticity](http://www.statsmakemecry.com/smmctheblog/confusing-stats-terms-explained-heteroscedasticity-heteroske.html)
- [Here](http://math.arizona.edu/~calc/Text/Section12.3.pdf) Contours are elegantly introduced.)


## Lecture 4 Summary (Linear Regression Lines - Part II)
- Hypothesis test - test of significance on regression coefficients
- p-values
- Capture non-linearity using Linear Regression lines.
- R-squared
- Interaction Effects

**Resources**
 
- [Lecture 4 - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%204%20-%20Regression%20-%20Part%202.pptx) 
- [Linear Regression - Part II - Lab Codes](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%204%20-%20Linear%20Regression%20-%20Part%202.ipynb) 
- [Linear Regression - Part II - Practice Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture%204-Practice-Code.ipynb)
- [Linear Regression - Part II - Practice Solution](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture4-Practice-Solution.ipynb)

**Additional Resources**

- My videos on regression lines. [Video 1](https://www.youtube.com/watch?v=QRzaKZRqens), [Video 2](https://www.youtube.com/watch?v=F6ceTd56vc0)
- This is an [excellent book](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf). In Lecture 3 and Lecture 4, we covered Chapter 3 of this textbook.
- [statmodels.formula.api](http://statsmodels.sourceforge.net/devel/)

**HW 2 is Assigned**

 - Please read and follow instructions from [readme](https://github.com/ga-students/DS-SF-24/blob/master/HW%20Assignments/HW2/readme.md)
 - [Here](https://github.com/ga-students/DS-SF-24/blob/master/HW%20Assignments/HW2/HW2-Starter-Code.ipynb) you can find iPython notebook of your 2nd assignment.
 - This homework is due on June 30th, 2016 at 6:30PM

## Lecture 5 Summary (Model Selection)

- Bias-Variance Trade off
- Validation (Test vs Train set)
- Cross-Validation
- Ridge and Lasso Regression
- (Optional) Backward Selection, Forward Selection, All Subset Selection. (If you want to use these methods you need to use R)

**Resources**
 
 - [Lecture 5 - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%205%20-%20Model%20Selection.pptx) 
 - [Model Selection - Lab Codes](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture5-Model_Selection.ipynb) 
 - [Model Selection  - Practice Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture5-Practice-Code.ipynb) 
 - [Model Selection - Practice Solutions](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture5-Practice-Solution.ipynb)
 - [HW 1 - Key](https://github.com/ga-students/DS-SF-24/blob/master/HW%20Assignments/HW1/HW1-Key.ipynb)
 
 
**Additional Resources**
 
 - [Preprocessing](http://scikit-learn.org/stable/modules/preprocessing.html) Library
 - [Cross-Validation](http://scikit-learn.org/stable/modules/cross_validation.html) Library
 - This is an [excellent book](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf). You can find theory of Cross-Validation in Chapter 5. You can also learn about Lasso and Ridge regression in Chapter 6 of the mentioend textbook.
 - [Here](https://www.youtube.com/watch?v=oTeXrcyaqKA) you can find my video on Cross-Validation
 - [Here](https://www.youtube.com/watch?v=2KTRa3QKvMY) you can find my video on Ridge and Lasso Regression
 - [Here](https://www.youtube.com/watch?v=fV1LQV0bQTU) you can find my video on Best subset selection.
 
## Lecture 6 Summary (Missing Data and Imputation)

- Types of missing data (MCAR, MAR, NMAR)
- Single imputation and their limitations
- Imuptation using regression lines and error
- Hot deck imputation
- multiple imputation

**Resources**
 
- [Lecture 6 - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%206-Missing%20Data-Imputation.pptx) 
- [Missing Data and Imputation - Lab Codes](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture6-MissingData.ipynb) 
- [Missing Data and Imputation  - Practice Code and HW 3](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture6-Practice-Code.ipynb) 

**Additional Resources**

- Great [Video](https://www.youtube.com/watch?v=xnQ17bbSeEk) by Dr. Elizabeth A. Stuart from John Hopkins University

**Announcements**

- **HW 3 is assigned** (Due at 6:30PM - July 7th)
- Please read [this](https://github.com/ga-students/DS-SF-24/blob/master/HW%20Assignments/HW3/readme.md) before starting your assignment.
- HW3 starter code can be found [here](https://github.com/ga-students/DS-SF-24/blob/master/HW%20Assignments/HW3/HW3-Starter-code.ipynb)

## Lecture 7 Summary (K-Nearest Neighbors)

- Classification Problems
- Misclassifciation Error
- KNN algorithm for Classification
- Cross-Validation for KNN Algorithm
- Limitations of KNN Algorithm
- KNN algorithm for Regression

**Resources**
 
- [Lecture 7 - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%207%20-%20KNN.pptx) 
- [K-Nearest Neighbors - Lab Codes](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture7-KNN.ipynb) 
- [K-Nearest Neighbors  - Practice Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture7-Practice-Code.ipynb) 
- [K-Nearest Neighbors - Practice Solution](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture7-Practice-Solution.ipynb)

**Announcements**

- [HW 2 Solutions](https://github.com/ga-students/DS-SF-24/blob/master/HW%20Assignments/HW2/HW2-Solution.ipynb) are posted.

## Lecture 8 Summary (Logistic Regression Part I)

- Logistic Regression - Intro
- Odds vs Probability
- Using Logistic Regression to Make predictions
- How one interprets coefficients of a Logistic Regression model
- Strength and weaknesses of Logistic Regression Model

**Resources**
 
- [Lecture 8 - Slides](https://github.com/ga-students/DS-SF-24/blob/master/Lecture%20Notes-Slides/Lecture%208-Logistic_Regression_Part%20I.pptx) 
- [Logistic Regression Part I - Lab Codes](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture8.ipynb) 
- [Logistic Regression Part I - Practice Code](https://github.com/ga-students/DS-SF-24/blob/master/Code/Lecture8-Practice-Code.ipynb) 

**Additional Resources**

- Logistic Regression [video](https://www.youtube.com/watch?time_continue=374&v=r-yv6GbWep4)